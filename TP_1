# Rappel Th√©orique : R√©gression Polynomiale, MSE et Descente de Gradient

---

## 1. R√âGRESSION POLYNOMIALE

### 1.1 Principe de base

**Objectif :** Trouver une fonction polynomiale qui approxime au mieux la relation entre une variable d'entr√©e **x** et une sortie **y**.

### 1.2 Mod√®le math√©matique

**Polyn√¥me d'ordre m :**

```
y(x) = Œ∏‚ÇÄ + Œ∏‚ÇÅx + Œ∏‚ÇÇx¬≤ + Œ∏‚ÇÉx¬≥ + ... + Œ∏‚Çòx·µê
```

O√π :
- **Œ∏ = [Œ∏‚ÇÄ, Œ∏‚ÇÅ, Œ∏‚ÇÇ, ..., Œ∏‚Çò]·µÄ** : vecteur de param√®tres (coefficients)
- **m** : ordre du polyn√¥me (degr√©)
- **Œ∏‚ÇÄ** : terme constant (biais/intercept)
- **Œ∏‚ÇÅ, Œ∏‚ÇÇ, ...** : coefficients des puissances de x

### 1.3 Formulation matricielle

Pour **N √©chantillons** {(x‚ÇÅ,y‚ÇÅ), (x‚ÇÇ,y‚ÇÇ), ..., (x‚Çô,y‚Çô)} :

**Vecteur des observations :**
```
Y = [y‚ÇÅ, y‚ÇÇ, ..., y‚Çô]·µÄ    (dimension N√ó1)
```

**Matrice de design X :**
```
X = [1  x‚ÇÅ  x‚ÇÅ¬≤  ...  x‚ÇÅ·µê]     (dimension N√ó(m+1))
    [1  x‚ÇÇ  x‚ÇÇ¬≤  ...  x‚ÇÇ·µê]
    [‚ãÆ   ‚ãÆ   ‚ãÆ   ‚ãÆ    ‚ãÆ  ]
    [1  x‚Çô  x‚Çô¬≤  ...  x‚Çô·µê]
```

**Pr√©dictions :**
```
≈∂ = XŒ∏
```

### 1.4 Exemples concrets

**Ordre 1 (r√©gression lin√©aire) :**
```
y(x) = Œ∏‚ÇÄ + Œ∏‚ÇÅx
‚Üí Droite
```

**Ordre 2 (parabolique) :**
```
y(x) = Œ∏‚ÇÄ + Œ∏‚ÇÅx + Œ∏‚ÇÇx¬≤
‚Üí Parabole
```

**Ordre 3 (cubique) :**
```
y(x) = Œ∏‚ÇÄ + Œ∏‚ÇÅx + Œ∏‚ÇÇx¬≤ + Œ∏‚ÇÉx¬≥
‚Üí Courbe avec 1 point d'inflexion
```

### 1.5 Illustration visuelle

```
Ordre 1:  ___/          (sous-ajust√© pour une sinuso√Øde)
         
Ordre 3:   ‚àø‚àø           (bon compromis)

Ordre 9:  ‚àø‚àø‚àø‚àø‚àø‚àø‚àø‚àø     (sur-ajust√©, oscillations)
```

---

## 2. MSE (Mean Squared Error)

### 2.1 D√©finition

La **MSE** (Erreur Quadratique Moyenne) est la fonction de co√ªt la plus utilis√©e en r√©gression.

**Formule :**
```
MSE(Œ∏) = 1/N Œ£·µ¢‚Çå‚ÇÅ·¥∫ (y·µ¢ - ≈∑·µ¢)¬≤
       = 1/N Œ£·µ¢‚Çå‚ÇÅ·¥∫ (y·µ¢ - y(x·µ¢))¬≤
```

O√π :
- **y·µ¢** : valeur r√©elle
- **≈∑·µ¢ = y(x·µ¢)** : pr√©diction du mod√®le
- **N** : nombre d'√©chantillons

### 2.2 Forme matricielle

```
MSE(Œ∏) = 1/N ||Y - XŒ∏||¬≤
       = 1/N (Y - XŒ∏)·µÄ(Y - XŒ∏)
```

### 2.3 Pourquoi l'√©l√©vation au carr√© ?

**Avantages :**
1. ‚úÖ **Toujours positive** : pas d'annulation entre erreurs positives/n√©gatives
2. ‚úÖ **P√©nalise fortement les grandes erreurs** : (erreur)¬≤
3. ‚úÖ **Diff√©rentiable partout** : calcul de gradient facile
4. ‚úÖ **Convexe** (pour r√©gression lin√©aire) : un seul minimum global
5. ‚úÖ **Interpr√©tation statistique** : estimateur du maximum de vraisemblance sous hypoth√®se gaussienne

**Illustration :**
```
Erreur: -2  -1   0   1   2
MSE:     4   1   0   1   4
‚Üí P√©nalise sym√©triquement et quadratiquement
```

### 2.4 Variantes de la MSE

**RMSE (Root MSE) :**
```
RMSE = ‚àöMSE
‚Üí M√™me unit√© que y (interpr√©tation plus facile)
```

**MSE avec r√©gularisation L2 (Ridge) :**
```
MSE_ridge(Œ∏) = 1/N Œ£·µ¢‚Çå‚ÇÅ·¥∫ (y·µ¢ - ≈∑·µ¢)¬≤ + Œª Œ£‚±º‚Çå‚ÇÄ·µê Œ∏‚±º¬≤
```
- **Œª > 0** : coefficient de r√©gularisation
- P√©nalise les param√®tres Œ∏ de grande amplitude
- √âvite le sur-apprentissage

### 2.5 Exemple num√©rique

```python
# Donn√©es
y_true = [1.0, 2.0, 3.0]
y_pred = [1.1, 2.3, 2.8]

# Calcul MSE
erreurs = [(1.0-1.1)¬≤, (2.0-2.3)¬≤, (3.0-2.8)¬≤]
        = [0.01, 0.09, 0.04]
MSE = (0.01 + 0.09 + 0.04) / 3 = 0.047
```

---

## 3. DESCENTE DE GRADIENT (Gradient Descent)

### 3.1 Principe fondamental

**Id√©e :** Minimiser it√©rativement la fonction de co√ªt en se d√©pla√ßant dans la direction oppos√©e au gradient.

**Analogie :** Descendre une montagne dans le brouillard
- On ne voit que localement (gradient)
- On fait des petits pas vers le bas
- On s'arr√™te quand on ne peut plus descendre

### 3.2 L'algorithme

**Initialisation :**
```
Œ∏‚ÅΩ‚Å∞‚Åæ = valeurs al√©atoires (ou z√©ros)
t = 0  (it√©ration)
```

**Mise √† jour it√©rative :**
```
Œ∏‚ÅΩ·µó‚Å∫¬π‚Åæ = Œ∏‚ÅΩ·µó‚Åæ - Œ± √ó ‚àáMSE(Œ∏‚ÅΩ·µó‚Åæ)
```

O√π :
- **Œ±** : learning rate (taux d'apprentissage)
- **‚àáMSE(Œ∏)** : gradient de la MSE par rapport √† Œ∏
- **t** : num√©ro d'it√©ration

**Arr√™t :**
- Apr√®s un nombre fixe d'√©poques
- Quand le gradient devient tr√®s petit
- Quand la loss ne diminue plus

### 3.3 Calcul du gradient

**Pour la MSE :**
```
MSE(Œ∏) = 1/N ||Y - XŒ∏||¬≤
```

**Gradient par rapport √† Œ∏ :**
```
‚àáMSE(Œ∏) = -2/N X·µÄ(Y - XŒ∏)
        = -2/N X·µÄe    o√π e = Y - XŒ∏ (erreurs)
```

**Pour chaque param√®tre Œ∏‚±º :**
```
‚àÇMSE/‚àÇŒ∏‚±º = -2/N Œ£·µ¢‚Çå‚ÇÅ·¥∫ (y·µ¢ - ≈∑·µ¢) √ó x·µ¢‚±º
```

### 3.4 Mise √† jour d√©taill√©e

**Formule compl√®te :**
```
Œ∏‚±º‚ÅΩ·µó‚Å∫¬π‚Åæ = Œ∏‚±º‚ÅΩ·µó‚Åæ + Œ± √ó (2/N) √ó Œ£·µ¢‚Çå‚ÇÅ·¥∫ (y·µ¢ - ≈∑·µ¢) √ó x·µ¢‚±º
```

**Interpr√©tation :**
- Si **erreur positive** (sous-estimation) ‚Üí augmenter Œ∏‚±º
- Si **erreur n√©gative** (sur-estimation) ‚Üí diminuer Œ∏‚±º
- Proportionnel √† la feature x·µ¢‚±º

### 3.5 Le learning rate (Œ±)

**R√¥le crucial :**

```
Œ± trop petit:  Œ∏ ---‚Ä¢---‚Ä¢---‚Ä¢---‚Ä¢---‚Ä¢‚Üí  (convergence lente)

Œ± optimal:     Œ∏ -----‚Ä¢-----‚Ä¢-----‚Üí    (convergence rapide)

Œ± trop grand:  Œ∏ ‚Ä¢---------‚Ä¢          (divergence)
                   \       /
                    \     /
                     \   /
                      \ /
```

**Valeurs typiques :**
- 10‚Åª¬π √† 10‚Åª‚Å∂ selon le probl√®me
- Dans le TP : **Œ± = 10‚Åª¬≥** est un bon d√©part

### 3.6 Variantes de la descente de gradient

**1. Batch Gradient Descent (BGD) :**
```
Utilise TOUS les √©chantillons √† chaque it√©ration
‚àáMSE = moyenne sur N √©chantillons
+ Convergence stable
- Lent pour grands datasets
```

**2. Stochastic Gradient Descent (SGD) :**
```
Utilise UN SEUL √©chantillon al√©atoire √† chaque it√©ration
‚àáMSE ‚âà gradient sur 1 exemple
+ Tr√®s rapide
+ Peut √©chapper minima locaux (bruit)
- Convergence bruit√©e
```

**3. Mini-Batch Gradient Descent :**
```
Utilise un PETIT LOT (ex: 32, 64, 128) d'√©chantillons
‚àáMSE = moyenne sur batch_size √©chantillons
+ Compromis vitesse/stabilit√©
+ Exploite parall√©lisation GPU
‚Üí STANDARD en deep learning
```

### 3.7 Illustration de la convergence

```
MSE
 |
 |  ‚Ä¢
 |   \
 |    ‚Ä¢\
 |      \‚Ä¢
 |        \‚Ä¢
 |          ‚Ä¢---‚Ä¢---‚Ä¢---  (convergence)
 +-------------------------> It√©rations
```

**Avec r√©gularisation L2 :**
```python
# Gradient avec weight decay
Œ∏‚ÅΩ·µó‚Å∫¬π‚Åæ = Œ∏‚ÅΩ·µó‚Åæ - Œ± √ó (‚àáMSE(Œ∏‚ÅΩ·µó‚Åæ) + ŒªŒ∏‚ÅΩ·µó‚Åæ)
       = (1 - Œ±Œª)Œ∏‚ÅΩ·µó‚Åæ - Œ±‚àáMSE(Œ∏‚ÅΩ·µó‚Åæ)
```
‚Üí D√©croissance des poids √† chaque it√©ration

### 3.8 Pseudo-code complet

```python
# Initialisation
Œ∏ = np.random.randn(m+1, 1)  # Param√®tres al√©atoires
Œ± = 1e-3                      # Learning rate
epochs = 5000                 # Nombre d'it√©rations

# Boucle d'apprentissage
for epoch in range(epochs):
    # Forward pass (pr√©diction)
    y_pred = X @ Œ∏
    
    # Calcul de l'erreur
    erreur = y_pred - Y
    
    # Calcul du gradient
    gradient = (2/N) * X.T @ erreur
    
    # Mise √† jour des param√®tres
    Œ∏ = Œ∏ - Œ± * gradient
    
    # (Optionnel) Calcul de la MSE
    mse = np.mean(erreur**2)
    
    # (Optionnel) R√©gularisation L2
    if weight_decay > 0:
        Œ∏ = Œ∏ - Œ± * weight_decay * Œ∏
```

---

## 4. COMPARAISON : Moindres Carr√©s vs Descente de Gradient

### 4.1 Tableau comparatif

| Aspect | Moindres Carr√©s | Descente Gradient |
|--------|-----------------|-------------------|
| **Solution** | Œ∏* = (X·µÄX + ŒªI)‚Åª¬πX·µÄY | It√©rative |
| **Calcul** | 1 op√©ration | Milliers d'it√©rations |
| **Complexit√©** | O(m¬≤N + m¬≥) | O(Nm √ó epochs) |
| **Convergence** | Imm√©diate | Progressive |
| **Optimum** | Global exact | Approch√© |
| **Hyperparam√®tres** | Œª seulement | Œ±, epochs, batch_size, Œª |
| **Scalabilit√©** | Limit√©e (m√©moire) | Excellente (mini-batch) |

### 4.2 Quand utiliser quoi ?

**Moindres Carr√©s si :**
- Dataset petit/moyen (N < 100,000)
- Features peu nombreuses (m < 1,000)
- Besoin de solution exacte rapide
- Mod√®le lin√©aire en Œ∏

**Descente de Gradient si :**
- Dataset tr√®s grand (millions)
- Beaucoup de features
- Mod√®le non-lin√©aire (deep learning)
- Apprentissage en ligne

---

## 5. APPLICATION AU TP

### 5.1 Le probl√®me

**Donn√©es :**
```python
# Vraie fonction (inconnue en pratique)
y = sin(2œÄx) + bruit_gaussien

# N=10 √©chantillons d'apprentissage
# N=10 √©chantillons de validation
```

**Objectif :**
Trouver le polyn√¥me qui approxime au mieux cette sinuso√Øde.

### 5.2 Pipeline complet

**√âtape 1 : G√©n√©ration des features**
```python
X = [1, x, x¬≤, x¬≥, ..., x·µê]  # Matrice de design
```

**√âtape 2 : Choix de la m√©thode**

*Option A - Moindres Carr√©s :*
```python
Œ∏* = np.linalg.inv(X.T @ X + Œª*I) @ X.T @ Y
y_pred = X @ Œ∏*
```

*Option B - Descente de Gradient :*
```python
model = NeuralNetwork(input_features=m)
optimizer = torch.optim.SGD(lr=1e-3, weight_decay=Œª)
# Boucle d'entra√Ænement sur epochs
```

**√âtape 3 : √âvaluation**
```python
mse_train = np.mean((Y_train - y_pred_train)**2)
mse_valid = np.mean((Y_valid - y_pred_valid)**2)
```

**√âtape 4 : Choix du mod√®le**
```
Tester m = 1, 2, 3, ..., 9
Choisir m qui minimise mse_valid
```

### 5.3 Ce que vous allez observer

**Avec m qui augmente :**
1. **m = 1** : Droite, mauvais fit (biais √©lev√©)
2. **m = 3-4** : Bonne approximation de la sinuso√Øde ‚úÖ
3. **m = 9** : Oscillations extr√™mes (variance √©lev√©e)

**Avec Œª (r√©gularisation) :**
- Œª = 0 : Sur-apprentissage pour m √©lev√©
- Œª = 0.01 : Courbes plus lisses
- Œª = 0.1 : Sous-apprentissage (trop de r√©gularisation)

**Avec le learning rate (descente gradient) :**
- Œ± = 10‚Åª¬≤ : Divergence possible
- Œ± = 10‚Åª¬≥ : Convergence stable
- Œ± = 10‚Åª‚Åµ : Convergence tr√®s lente

---

## 6. FORMULES CL√âS √Ä RETENIR

### R√©gression polynomiale
```
≈∑ = Œ∏‚ÇÄ + Œ∏‚ÇÅx + Œ∏‚ÇÇx¬≤ + ... + Œ∏‚Çòx·µê
≈∂ = XŒ∏
```

### MSE
```
MSE = (1/N) Œ£(y·µ¢ - ≈∑·µ¢)¬≤
MSE_ridge = MSE + ŒªŒ£Œ∏‚±º¬≤
```

### Moindres carr√©s
```
Œ∏* = (X·µÄX + ŒªI)‚Åª¬πX·µÄY
```

### Descente de gradient
```
Œ∏‚ÅΩ·µó‚Å∫¬π‚Åæ = Œ∏‚ÅΩ·µó‚Åæ - Œ±‚àáMSE(Œ∏‚ÅΩ·µó‚Åæ)
‚àáMSE = (2/N)X·µÄ(XŒ∏ - Y)
```

---

## 7. POINTS CL√âS POUR LE TP

‚úÖ **Comprendre** que r√©gression polynomiale = r√©gression lin√©aire dans l'espace des features [1, x, x¬≤, ...]

‚úÖ **Observer** le compromis biais-variance en faisant varier m

‚úÖ **Exp√©rimenter** l'effet de la r√©gularisation Œª

‚úÖ **Comparer** moindres carr√©s (exact, rapide) vs gradient descent (it√©ratif, flexible)

‚úÖ **Ma√Ætriser** l'influence du learning rate sur la convergence

‚úÖ **Visualiser** syst√©matiquement les courbes et les erreurs

---

**Questions ?** ü§î
