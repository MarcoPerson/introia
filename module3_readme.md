# ğŸ¯ Module 3 : Classification et Analyse de Sentiments
## *CrÃ©er une IA qui dÃ©tecte les Ã©motions comme un psychologue*

---

## ğŸ“¹ **VidÃ©o d'Introduction** *(5 minutes)*

> **ğŸ¬ Script de la vidÃ©o :**
> 
> "Salut les futurs experts NLP ! Imaginez pouvoir analyser automatiquement des milliers d'avis clients en quelques secondes pour savoir s'ils sont contents ou furieux. C'est exactement ce qu'on va crÃ©er dans ce module !
> 
> Vous allez apprendre les secrets des algorithmes de classification - ces petites merveilles mathÃ©matiques qui transforment votre machine en dÃ©tective Ã©motionnel. De Naive Bayes (oui, il est vraiment 'naÃ¯f' mais diablement efficace !) aux forÃªts alÃ©atoires, vous maÃ®triserez l'art de faire comprendre les nuances humaines Ã  un ordinateur.
> 
> Ã€ la fin de ce module, vous aurez crÃ©Ã© un analyseur de sentiments capable de traiter du texte en temps rÃ©el et de vous dire si vos utilisateurs sont aux anges ou sur le point d'exploser. PrÃªts Ã  devenir des chuchoteurs d'Ã©motions digitales ? C'est parti !"

**ğŸ¯ Ce que vous allez apprendre :**
- Transformer des textes en catÃ©gories (positif/nÃ©gatif/neutre)
- EntraÃ®ner des modÃ¨les qui "comprennent" les Ã©motions
- Ã‰valuer la performance de vos IA avec des mÃ©triques pro
- CrÃ©er un analyseur de sentiments dÃ©ployable

**â±ï¸ DurÃ©e estimÃ©e :** 4-5 heures  
**ğŸ–ï¸ Niveau :** IntermÃ©diaire  
**ğŸ› ï¸ PrÃ©requis :** Modules 1 & 2 terminÃ©s

---

## ğŸ“‹ **Plan du Module**

| Section | Contenu | DurÃ©e | Type |
|---------|---------|-------|------|
| **ThÃ©orie** | 5 chapitres concepts | 2h | ğŸ“š Lecture |
| **Exercices** | 4 exercices pratiques | 2h | ğŸ’» Code |
| **Projet** | Analyseur complet | 1h | ğŸš€ IntÃ©gration |

---

## ğŸ“š **1. Classification SupervisÃ©e - Les Fondations**

### ğŸ¯ **Objectif**
Comprendre comment une machine peut apprendre Ã  catÃ©goriser automatiquement du texte en se basant sur des exemples.

### ğŸ“– **Le Principe de Base**

L'apprentissage supervisÃ©, c'est comme apprendre Ã  reconnaÃ®tre les races de chiens :

```
ğŸ‘¨â€ğŸ« PHASE D'ENTRAÃNEMENT
Humain : "Ã‡a c'est un Labrador" (montre photo + Ã©tiquette)
Humain : "Ã‡a c'est un Bulldog" (montre photo + Ã©tiquette)
Machine : *analyse les patterns* ğŸ¤–

ğŸ¯ PHASE DE PRÃ‰DICTION  
Humain : "C'est quelle race ?" (montre nouvelle photo)
Machine : "Je pense que c'est un Labrador Ã  85%" ğŸ²
```

**En NLP, on fait pareil avec le texte :**

```python
# Phase d'entraÃ®nement
textes_exemples = [
    "Ce produit est fantastique !",      # â†’ positif
    "TrÃ¨s dÃ©Ã§u de cet achat",           # â†’ nÃ©gatif  
    "Ã‡a va, sans plus",                 # â†’ neutre
]

# Phase de prÃ©diction
nouveau_texte = "J'adore cette app !"
prediction = modele.predict(nouveau_texte)  # â†’ positif (92%)
```

### ğŸ”¢ **Types de Classification**

#### **Classification Binaire**
2 catÃ©gories seulement (comme un interrupteur ON/OFF)
```
ğŸ˜Š Positif  |  ğŸ˜¡ NÃ©gatif
```

#### **Classification Multi-Classe**
3+ catÃ©gories exclusives (comme choisir une couleur)
```
ğŸ˜Š Positif  |  ğŸ˜¡ NÃ©gatif  |  ğŸ˜ Neutre
```

#### **Classification Multi-Label**
Plusieurs Ã©tiquettes possibles (comme les tags d'un article)
```
ğŸ˜Š Positif + ğŸ˜ Enthousiaste + ğŸ›’ Achat
```

### ğŸ“Š **Train/Validation/Test Split**

**Pourquoi diviser ses donnÃ©es ?**

Imaginez que vous prÃ©parez un examen :
- **ğŸ“š Train (70%)** : Vos cours pour apprendre
- **ğŸ“ Validation (15%)** : Vos exercices pour vous tester
- **ğŸ“ Test (15%)** : L'examen final (jamais vu avant !)

```python
from sklearn.model_selection import train_test_split

# Division intelligente des donnÃ©es
X_train, X_temp, y_train, y_temp = train_test_split(
    textes, sentiments, test_size=0.3, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

print(f"ğŸ“š Train: {len(X_train)} exemples")
print(f"ğŸ“ Validation: {len(X_val)} exemples") 
print(f"ğŸ“ Test: {len(X_test)} exemples")
```

### âš ï¸ **PiÃ¨ges Courants Ã  Ã‰viter**

**ğŸš« Data Leakage :** Utiliser les donnÃ©es de test pendant l'entraÃ®nement
```python
# âŒ MAUVAIS
modele.fit(X_train + X_test, y_train + y_test)  # Triche !

# âœ… BON  
modele.fit(X_train, y_train)  # Apprentissage honnÃªte
```

**ğŸš« Overfitting :** Apprendre par cÅ“ur au lieu de comprendre
```python
# SymptÃ´me : 99% sur train, 60% sur test
# Solution : rÃ©gularisation, plus de donnÃ©es, validation croisÃ©e
```

---

## ğŸ“Š **2. PrÃ©paration des DonnÃ©es - La Cuisine SecrÃ¨te**

### ğŸ¯ **Objectif**
Transformer vos donnÃ©es brutes en festin pour algorithmes affamÃ©s.

### ğŸ“‹ **Collecte et Annotation**

#### **Sources de DonnÃ©es Textuelles**
```python
sources_donnees = {
    "ğŸ›’ E-commerce": ["Amazon", "Fnac", "Cdiscount"],
    "ğŸ¬ Divertissement": ["AlloCinÃ©", "Netflix", "Spotify"], 
    "ğŸ¨ Services": ["TripAdvisor", "Booking", "Uber"],
    "ğŸ“± Apps": ["App Store", "Google Play"],
    "ğŸ¦ Social": ["Twitter", "Facebook", "Reddit"]
}
```

#### **Annotation Manuelle - Les RÃ¨gles d'Or**

**ğŸ“ Ã‰chelle de Sentiment :**
```
ğŸ˜¡ TrÃ¨s NÃ©gatif (-2) : "Je dÃ©teste, c'est nul !"
ğŸ˜ NÃ©gatif (-1)       : "Pas terrible, dÃ©Ã§u"  
ğŸ˜ Neutre (0)         : "Ã‡a va, correct"
ğŸ™‚ Positif (+1)       : "Bien, satisfait"
ğŸ˜ TrÃ¨s Positif (+2) : "Fantastique, j'adore !"
```

**ğŸ¯ CritÃ¨res d'Annotation :**
- **Intention** : Que veut exprimer la personne ?
- **Contexte** : Sarcasme, ironie, second degrÃ© ?
- **IntensitÃ©** : LÃ©gÃ¨rement vs extrÃªmement positif/nÃ©gatif

#### **Cas Complexes**

```python
exemples_pieges = [
    {
        "texte": "Ce produit n'est pas mauvais du tout !",
        "piege": "Double nÃ©gation = positif",
        "label": "positif"
    },
    {
        "texte": "Vraiment 'fantastique' ce service...",  
        "piege": "Guillemets = sarcasme probable",
        "label": "nÃ©gatif"
    },
    {
        "texte": "Bon produit mais livraison horrible",
        "piege": "Sentiment mixte sur 2 aspects",
        "label": "neutre"  # ou sÃ©parer en 2 phrases
    }
]
```

### âš–ï¸ **Ã‰quilibrage des Classes**

#### **Le ProblÃ¨me du DÃ©sÃ©quilibre**
```python
# âŒ Dataset dÃ©sÃ©quilibrÃ©  
distribution_naive = {
    "positif": 8000,   # 80% - MajoritÃ© Ã©crasante
    "neutre": 1500,    # 15% 
    "nÃ©gatif": 500     # 5% - MinoritÃ© nÃ©gligÃ©e
}

# ProblÃ¨me : Le modÃ¨le va toujours prÃ©dire "positif" !
```

#### **Solutions d'Ã‰quilibrage**

**ğŸ¯ Under-sampling :** RÃ©duire la majoritÃ©
```python
from imblearn.under_sampling import RandomUnderSampler

undersampler = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = undersampler.fit_resample(X, y)

# RÃ©sultat : 500 exemples de chaque classe
```

**ğŸ¯ Over-sampling :** Augmenter la minoritÃ©  
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# RÃ©sultat : 8000 exemples de chaque classe (SMOTE gÃ©nÃ¨re des exemples synthÃ©tiques)
```

**ğŸ¯ PondÃ©ration des Classes :** Dire au modÃ¨le que certaines erreurs coÃ»tent plus cher
```python
from sklearn.naive_bayes import MultinomialNB

# Le modÃ¨le pÃ©nalise plus les erreurs sur les classes rares
modele = MultinomialNB(class_weight='balanced')
```

### ğŸ§¹ **Nettoyage SpÃ©cialisÃ© pour Classification**

```python
import re
import string
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

def preprocesser_pour_classification(texte):
    """
    Pipeline de nettoyage optimisÃ© pour l'analyse de sentiments
    """
    # 1. PrÃ©server les Ã©motions importantes
    texte = re.sub(r'[!]{2,}', ' trÃ¨s_excite ', texte)  # !!! â†’ trÃ¨s_excite
    texte = re.sub(r'[?]{2,}', ' trÃ¨s_confus ', texte)   # ??? â†’ trÃ¨s_confus
    
    # 2. GÃ©rer les nÃ©gations (CRUCIAL pour sentiments!)
    texte = re.sub(r"n'|ne ", " ne_pas ", texte)
    texte = re.sub(r" pas ", " ne_pas ", texte)
    
    # 3. Normaliser les intensifiants
    texte = re.sub(r'trÃ¨s trÃ¨s', 'extrÃªmement', texte)
    texte = re.sub(r'super ', 'trÃ¨s ', texte)
    
    # 4. Nettoyer sans dÃ©truire le sens
    texte = re.sub(r'http\S+', '', texte)  # URLs
    texte = re.sub(r'@\w+', '', texte)     # Mentions
    texte = re.sub(r'#(\w+)', r'\1', texte)  # Hashtags â†’ mots
    
    # 5. Normalisation finale
    texte = texte.lower()
    texte = re.sub(r'[^\w\s]', ' ', texte)
    texte = ' '.join(texte.split())  # Espaces multiples
    
    return texte

# Test
exemple = "Ce produit n'est pas terrible... vraiment pas !!! #dÃ©Ã§u"
print(preprocesser_pour_classification(exemple))
# Output: "ce produit ne_pas est ne_pas terrible vraiment ne_pas trÃ¨s_excite dÃ©Ã§u"
```

---

## ğŸ¤– **3. Algorithmes de Classification - L'Arsenal**

### ğŸ¯ **Objectif**  
MaÃ®triser les 3 algorithmes stars de la classification de texte et savoir quand les utiliser.

### ğŸ§  **Naive Bayes - Le GÃ©nie "NaÃ¯f"**

#### **Pourquoi "NaÃ¯f" ?**
Il assume que tous les mots sont indÃ©pendants (ce qui est faux, mais Ã§a marche !)

```python
# Naive Bayes pense que dans "trÃ¨s bon produit" :
# - "trÃ¨s" n'influence pas "bon"  
# - "bon" n'influence pas "produit"
# C'est naÃ¯f, mais statistiquement efficace !
```

#### **Le Principe MathÃ©matique (SimplifiÃ©)**
```
P(sentiment|texte) = P(texte|sentiment) Ã— P(sentiment) / P(texte)

Traduction : 
"ProbabilitÃ© que ce soit positif sachant ce texte"
= 
"FrÃ©quence de ces mots dans les textes positifs" 
Ã— "Proportion de textes positifs globalement"
/ "FrÃ©quence de ces mots au total"
```

#### **ImplÃ©mentation Pratique**
```python
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer

# 1. PrÃ©paration des features
vectorizer = TfidfVectorizer(
    max_features=10000,      # Top 10k mots les + frÃ©quents
    ngram_range=(1, 2),      # Mots seuls + bigrammes  
    stop_words='english'     # Retire "le", "de", "et"...
)

X_train_vec = vectorizer.fit_transform(X_train)
X_val_vec = vectorizer.transform(X_val)

# 2. EntraÃ®nement  
nb_model = MultinomialNB(alpha=1.0)  # alpha = lissage de Laplace
nb_model.fit(X_train_vec, y_train)

# 3. PrÃ©diction
predictions = nb_model.predict(X_val_vec)
probabilities = nb_model.predict_proba(X_val_vec)

print(f"Exemple : {X_val[0]}")
print(f"PrÃ©diction : {predictions[0]}")  
print(f"Confiance : {max(probabilities[0]):.2%}")
```

#### **Avantages/InconvÃ©nients**
```python
avantages_nb = [
    "âš¡ TrÃ¨s rapide Ã  entraÃ®ner",
    "ğŸ“Š Fonctionne bien avec peu de donnÃ©es", 
    "ğŸ¯ Excellent baseline pour commencer",
    "ğŸ’¡ InterprÃ©table (on voit quels mots influencent)"
]

inconvenients_nb = [
    "ğŸ¤” Assume l'indÃ©pendance des mots (faux)",
    "ğŸ“ Ignore l'ordre des mots",
    "ğŸ­ Mal avec sarcasme/ironie complexe"
]
```

### ğŸ¯ **SVM - Les FrontiÃ¨res Optimales**

#### **L'IdÃ©e GÃ©niale**
SVM cherche la "frontiÃ¨re" parfaite qui sÃ©pare les classes avec la plus grande marge possible.

```python
# Visualisation 2D (simplifiÃ©)
"""
    ğŸ˜Š Positifs        |        ğŸ˜¡ NÃ©gatifs
         ğŸ˜Š            |            ğŸ˜¡
    ğŸ˜Š       ğŸ˜Š        |        ğŸ˜¡     ğŸ˜¡  
         ğŸ˜Š            |            ğŸ˜¡
                   FRONTIÃˆRE
                   (hyperplan)
"""
```

#### **Avantage Secret : Le Kernel Trick**
```python
from sklearn.svm import SVC

# SVM linÃ©aire : frontiÃ¨re droite
svm_linear = SVC(kernel='linear', C=1.0)

# SVM polynomial : frontiÃ¨re courbe  
svm_poly = SVC(kernel='poly', degree=3, C=1.0)

# SVM RBF : frontiÃ¨re trÃ¨s flexible
svm_rbf = SVC(kernel='rbf', gamma='scale', C=1.0)
```

#### **ImplÃ©mentation ComplÃ¨te**
```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

# 1. Recherche des meilleurs hyperparamÃ¨tres
param_grid = {
    'C': [0.1, 1, 10, 100],           # RÃ©gularisation
    'kernel': ['linear', 'rbf'],       # Type de kernel
    'gamma': ['scale', 'auto']         # Pour kernel RBF
}

svm_grid = GridSearchCV(
    SVC(probability=True),  # probability=True pour predict_proba
    param_grid, 
    cv=5,                   # Validation croisÃ©e 5-fold
    scoring='f1_weighted',  # MÃ©trique d'optimisation
    n_jobs=-1              # ParallÃ©lisation
)

# 2. EntraÃ®nement avec recherche d'hyperparamÃ¨tres
svm_grid.fit(X_train_vec, y_train)

# 3. Meilleur modÃ¨le
best_svm = svm_grid.best_estimator_
print(f"Meilleurs paramÃ¨tres : {svm_grid.best_params_}")
print(f"Score CV : {svm_grid.best_score_:.3f}")

# 4. Ã‰valuation finale
val_score = best_svm.score(X_val_vec, y_val)
print(f"Score validation : {val_score:.3f}")
```

### ğŸŒ³ **Random Forest - La Puissance Collective**

#### **Le Principe de la Sagesse des Foules**
```python
# Au lieu d'un seul arbre de dÃ©cision :
decision_tree_1 = "Je pense que c'est positif"
decision_tree_2 = "Je pense que c'est nÃ©gatif"  
decision_tree_3 = "Je pense que c'est positif"
# ... 100 arbres diffÃ©rents

# Random Forest fait voter :
vote_final = "MajoritÃ© dit positif â†’ POSITIF !"
```

#### **Pourquoi c'est Magique ?**
- Chaque arbre voit des donnÃ©es lÃ©gÃ¨rement diffÃ©rentes
- Chaque arbre utilise des features lÃ©gÃ¨rement diffÃ©rentes  
- Les erreurs individuelles se compensent
- RÃ©sultat : plus stable et robuste

#### **ImplÃ©mentation AvancÃ©e**
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# 1. Grid search randomisÃ© (plus efficace pour RF)
param_dist = {
    'n_estimators': [100, 200, 300, 500],        # Nombre d'arbres
    'max_depth': [10, 20, 30, None],             # Profondeur max
    'min_samples_split': [2, 5, 10],             # Split minimum  
    'min_samples_leaf': [1, 2, 4],               # Feuilles minimum
    'max_features': ['sqrt', 'log2', None],      # Features par split
    'bootstrap': [True, False]                   # Ã‰chantillonnage
}

rf_random = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_dist,
    n_iter=50,              # 50 combinaisons testÃ©es
    cv=3,                   # 3-fold CV (plus rapide)
    scoring='f1_weighted',
    n_jobs=-1,
    random_state=42
)

# 2. EntraÃ®nement
rf_random.fit(X_train_vec, y_train)
best_rf = rf_random.best_estimator_

# 3. Analyse de l'importance des features
feature_names = vectorizer.get_feature_names_out()
importances = best_rf.feature_importances_

# Top 10 mots les plus importants
top_features = sorted(
    zip(feature_names, importances), 
    key=lambda x: x[1], 
    reverse=True
)[:10]

print("ğŸ† Top 10 mots les plus discriminants :")
for mot, importance in top_features:
    print(f"{mot}: {importance:.4f}")
```

### ğŸ“Š **Comparaison des Algorithmes**

```python
comparaison_algos = {
    "CritÃ¨re": ["Vitesse", "PrÃ©cision", "InterprÃ©tabilitÃ©", "Peu de donnÃ©es", "Robustesse"],
    "Naive Bayes": ["ğŸŸ¢ TrÃ¨s rapide", "ğŸŸ¡ Correct", "ğŸŸ¢ Excellente", "ğŸŸ¢ TrÃ¨s bon", "ğŸŸ¡ Moyen"],
    "SVM": ["ğŸŸ¡ Moyen", "ğŸŸ¢ Excellent", "ğŸ”´ Faible", "ğŸŸ¡ Moyen", "ğŸŸ¢ TrÃ¨s bon"],
    "Random Forest": ["ğŸ”´ Lent", "ğŸŸ¢ Excellent", "ğŸŸ¡ Bonne", "ğŸ”´ Besoin de beaucoup", "ğŸŸ¢ Excellent"]
}
```

**ğŸ¯ Conseil du Pro :**
```python
strategie_choix = {
    "Prototype rapide": "Naive Bayes",
    "Performance maximale": "SVM + Grid Search", 
    "Ã‰quilibre perf/interprÃ©tabilitÃ©": "Random Forest",
    "Production avec gros volume": "Naive Bayes ou RF optimisÃ©"
}
```

---

## ğŸ”§ **4. Feature Engineering - L'Art du DÃ©tective**

### ğŸ¯ **Objectif**
CrÃ©er des features qui capturent les nuances Ã©motionnelles que les mots seuls ne rÃ©vÃ¨lent pas.

### ğŸ“Š **Features Linguistiques Basiques**

#### **Statistiques de Base**
```python
def extraire_features_basiques(texte):
    """Features simples mais puissantes"""
    
    features = {}
    
    # Longueur et structure
    features['nb_mots'] = len(texte.split())
    features['nb_caracteres'] = len(texte)
    features['mots_par_phrase'] = features['nb_mots'] / max(1, texte.count('.'))
    
    # Ponctuation Ã©motionnelle  
    features['nb_exclamations'] = texte.count('!')
    features['nb_questions'] = texte.count('?')
    features['ratio_majuscules'] = sum(1 for c in texte if c.isupper()) / max(1, len(texte))
    
    # IntensitÃ©
    features['mots_intensifiants'] = sum(1 for mot in ['trÃ¨s', 'super', 'extrÃªmement'] 
                                       if mot in texte.lower())
    
    return features

# Test
exemple = "Ce produit est VRAIMENT trÃ¨s dÃ©cevant !!! Pourquoi ?"
print(extraire_features_basiques(exemple))
```

#### **Features Ã‰motionnelles AvancÃ©es**

```python
# Lexiques de sentiments (Ã  charger depuis fichiers)
MOTS_POSITIFS = {'gÃ©nial', 'fantastique', 'parfait', 'excellent', 'satisfait'}
MOTS_NEGATIFS = {'nul', 'horrible', 'dÃ©cevant', 'mauvais', 'insatisfait'}
MOTS_INTENSITE = {'trÃ¨s', 'super', 'extrÃªmement', 'vraiment', 'totalement'}

def extraire_features_sentiment(texte):
    """Features spÃ©cialisÃ©es sentiment"""
    
    mots = texte.lower().split()
    features = {}
    
    # Comptage direct
    features['mots_positifs'] = sum(1 for mot in mots if mot in MOTS_POSITIFS)
    features['mots_negatifs'] = sum(1 for mot in mots if mot in MOTS_NEGATIFS)
    features['mots_intensite'] = sum(1 for mot in mots if mot in MOTS_INTENSITE)
    
    # Ratios  
    total_mots = len(mots)
    features['ratio_positif'] = features['mots_positifs'] / max(1, total_mots)
    features['ratio_negatif'] = features['mots_negatifs'] / max(1, total_mots)
    
    # Score global
    features['score_brut'] = features['mots_positifs'] - features['mots_negatifs']
    
    return features
```

### ğŸ”¤ **N-grammes - Capturer le Contexte**

#### **Pourquoi les N-grammes ?**
```python
phrase = "Ce produit n'est pas terrible"

# Unigrams (1-gramme) : mots isolÃ©s
unigrams = ["ce", "produit", "n'est", "pas", "terrible"]
# ProblÃ¨me : "terrible" semble nÃ©gatif, mais ici c'est positif !

# Bigrams (2-grammes) : paires de mots  
bigrams = ["ce produit", "produit n'est", "n'est pas", "pas terrible"]
# Mieux : "pas terrible" capture la nÃ©gation !

# Trigrams (3-grammes) : triplets
trigrams = ["ce produit n'est", "produit n'est pas", "n'est pas terrible"] 
# Parfait : "n'est pas terrible" = contexte complet !
```

#### **ImplÃ©mentation OptimisÃ©e**
```python
from sklearn.feature_extraction.text import TfidfVectorizer

# Configuration multi-niveau
vectorizer_ngrams = TfidfVectorizer(
    ngram_range=(1, 3),          # Unigrams + Bigrams + Trigrams
    max_features=20000,          # Garde les 20k plus importantes
    min_df=2,                    # Ignore mots qui apparaissent < 2 fois
    max_df=0.8,                  # Ignore mots qui apparaissent > 80% docs
    stop_words='french',         # Stop words franÃ§ais
    sublinear_tf=True           # log(tf) au lieu de tf (meilleure perf)
)

# Test de l'impact des n-grammes
def tester_ngrams():
    configurations = [
        (1, 1),    # Unigrams seulement
        (1, 2),    # Unigrams + Bigrams  
        (1, 3),    # Unigrams + Bigrams + Trigrams
        (2, 3)     # Bigrams + Trigrams seulement
    ]
    
    for ngram_range in configurations:
        vec = TfidfVectorizer(ngram_range=ngram_range, max_features=5000)
        X_transformed = vec.fit_transform(X_train)
        
        # Test rapide avec Naive Bayes
        nb = MultinomialNB()
        scores = cross_val_score(nb, X_transformed, y_train, cv=3)
        
        print(f"N-grams {ngram_range}: {scores.mean():.3f} Â± {scores.std():.3f}")
```

### âš¡ **Gestion des NÃ©gations - Le PiÃ¨ge Fatal**

#### **Le ProblÃ¨me Classique**
```python
# Ces deux phrases ont des mots similaires mais sens opposÃ©s !
phrase1 = "Ce produit est bon"          # POSITIF
phrase2 = "Ce produit n'est pas bon"    # NÃ‰GATIF

# Mais pour un modÃ¨le naÃ¯f : mots = ["ce", "produit", "est", "bon"]
# Il va prÃ©dire POSITIF pour les deux ! ğŸ˜±
```

#### **Solution : Transformation des NÃ©gations**
```python
import re

def transformer_negations(texte):
    """
    Transforme les nÃ©gations pour prÃ©server le sens
    """
    # Patterns de nÃ©gation franÃ§ais
    patterns_negation = [
        (r"n'est pas (\w+)", r"ne_pas_\1"),          # n'est pas bon â†’ ne_pas_bon
        (r"ne (\w+) pas", r"ne_pas_\1"),             # ne fonctionne pas â†’ ne_pas_fonctionne
        (r"pas du tout (\w+)", r"pas_du_tout_\1"),   # pas du tout satisfait â†’ pas_du_tout_satisfait
        (r"jamais (\w+)", r"jamais_\1"),             # jamais content â†’ jamais_content
        (r"aucun (\w+)", r"aucun_\1"),               # aucun intÃ©rÃªt â†’ aucun_intÃ©rÃªt
    ]
    
    for pattern, replacement in patterns_negation:
        texte = re.sub(pattern, replacement, texte, flags=re.IGNORECASE)
    
    return texte

# Test
exemples = [
    "Ce produit n'est pas terrible du tout",
    "Je ne recommande pas cet achat", 
    "Jamais satisfait de ce service",
    "Aucun problÃ¨me avec cette commande"
]

for ex in exemples:
    print(f"Avant : {ex}")
    print(f"AprÃ¨s : {transformer_negations(ex)}")
    print()
```

### ğŸ­ **Features Ã‰motionnelles AvancÃ©es**

#### **Analyse des Ã‰mojis**
```python
import emoji

def analyser_emojis(texte):
    """Extrait et analyse les Ã©mojis"""
    
    # Dictionnaire sentiment des Ã©mojis populaires
    emoji_sentiments = {
        'ğŸ˜Š': 1, 'ğŸ˜ƒ': 1, 'ğŸ˜„': 1, 'ğŸ™‚': 1, 'ğŸ˜': 2, 'ğŸ¥°': 2, 'ğŸ¤©': 2,
        'ğŸ˜': -1, 'ğŸ˜¢': -2, 'ğŸ˜­': -2, 'ğŸ˜¡': -2, 'ğŸ¤¬': -2, 'ğŸ˜ ': -2,
        'ğŸ¤”': 0, 'ğŸ˜': 0, 'ğŸ˜‘': 0
    }
    
    # Extraction des Ã©mojis
    emojis_trouves = [c for c in texte if c in emoji.UNICODE_EMOJI['en']]
    
    features = {
        'nb_emojis': len(emojis_trouves),
        'score_emoji': sum(emoji_sentiments.get(em, 0) for em in emojis_trouves),
        'ratio_emojis_positifs': sum(1 for em in emojis_trouves 
                                   if emoji_sentiments.get(em, 0) > 0) / max(1, len(emojis_trouves))
    }
    
    return features

# Test
exemple_emoji = "J'adore ce produit ! ğŸ˜ğŸ¤© Vraiment top ğŸ˜Š"
print(analyser_emojis(exemple_emoji))
```

#### **Pipeline ComplÃ¨te de Feature Engineering**
```python
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import FeatureUnion
import pandas as pd

class ExtracteurFeaturesCustom(BaseEstimator, TransformerMixin):
    """Extracteur de features personnalisÃ©es pour analyse de sentiments"""
    
    def __init__(self):
        self.feature_names = None
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        """Transforme une liste de textes en matrice de features"""
        
        features_list = []
        
        for texte in X:
            # PrÃ©processing
            texte_clean = transformer_negations(texte)
            
            # Extraction de toutes les features
            features = {}
            features.update(extraire_features_basiques(texte))
            features.update(extraire_features_sentiment(texte_clean))
            features.update(analyser_emojis(texte))
            
            features_list.append(features)
        
        # Conversion en DataFrame puis array numpy
        df_features = pd.DataFrame(features_list).fillna(0)
        self.feature_names = df_features.columns.tolist()
        
        return df_features.values
    
    def get_feature_names_out(self, input_features=None):
        return self.feature_names

# Utilisation dans un pipeline complet
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer

pipeline_complet = Pipeline([
    ('features', FeatureUnion([
        ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=10000)),
        ('custom', ExtracteurFeaturesCustom())
    ])),
    ('classifier', MultinomialNB())
])

# EntraÃ®nement et test
pipeline_complet.fit(X_train, y_train)
score = pipeline_complet.score(X_val, y_val)
print(f"Score avec features custom: {score:.3f}")
```

---

## ğŸ“Š **5. Ã‰valuation - Mesurer la Performance**

### ğŸ¯ **Objectif**
Comprendre si votre modÃ¨le est vraiment bon ou s'il vous fait illusion.

### ğŸ² **MÃ©triques Essentielles**

#### **Accuracy - La MÃ©trique PiÃ¨ge**
```python
# Accuracy = (PrÃ©dictions correctes) / (Total prÃ©dictions)

# âš ï¸ PIÃˆGE CLASSIQUE
donnees_desequilibrees = {
    "positif": 950,    # 95%
    "nÃ©gatif": 50      # 5%  
}

# Un modÃ¨le stupide qui dit toujours "positif" :
# Accuracy = 950/1000 = 95% â† IMPRESSIONNANT mais INUTILE !
```

#### **Precision, Recall, F1-Score - Les Vraies MÃ©triques**

```python
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

def evaluer_modele_complet(y_true, y_pred, labels=None):
    """Ã‰valuation complÃ¨te d'un modÃ¨le de classification"""
    
    # 1. Rapport de classification dÃ©taillÃ©
    print("ğŸ“Š RAPPORT DE CLASSIFICATION")
    print("=" * 50)
    report = classification_report(y_true, y_pred, target_names=labels)
    print(report)
    
    # 2. Matrice de confusion
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=labels, yticklabels=labels)
    plt.title('Matrice de Confusion')
    plt.xlabel('PrÃ©dictions')
    plt.ylabel('Vraies Ã‰tiquettes')
    plt.show()
    
    # 3. Analyse dÃ©taillÃ©e par classe
    print("\nğŸ” ANALYSE PAR CLASSE")
    print("=" * 30)
    
    for i, label in enumerate(labels):
        tp = cm[i, i]  # Vrais positifs
        fp = cm[:, i].sum() - tp  # Faux positifs  
        fn = cm[i, :].sum() - tp  # Faux nÃ©gatifs
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"{label.upper()}:")
        print(f"  Precision: {precision:.3f} (Sur 100 prÃ©dictions '{label}', {precision*100:.1f}% sont correctes)")
        print(f"  Recall: {recall:.3f} (Sur 100 vrais '{label}', {recall*100:.1f}% sont dÃ©tectÃ©s)")
        print(f"  F1-Score: {f1:.3f} (Moyenne harmonique des deux)")
        print()

# Utilisation
predictions = modele.predict(X_test)
evaluer_modele_complet(y_test, predictions, ['nÃ©gatif', 'neutre', 'positif'])
```

#### **Validation CroisÃ©e - Le Test de Robustesse**

```python
from sklearn.model_selection import cross_val_score, StratifiedKFold

def validation_croisee_complete(modele, X, y, cv=5):
    """Validation croisÃ©e avec analyse statistique"""
    
    # Configuration du cross-validation
    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)
    
    # Scores multiples
    metriques = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']
    resultats = {}
    
    for metrique in metriques:
        scores = cross_val_score(modele, X, y, cv=skf, scoring=metrique)
        resultats[metrique] = {
            'scores': scores,
            'moyenne': scores.mean(),
            'std': scores.std(),
            'intervalle': (scores.mean() - 2*scores.std(), scores.mean() + 2*scores.std())
        }
    
    # Affichage des rÃ©sultats
    print("ğŸ¯ VALIDATION CROISÃ‰E (5-FOLD)")
    print("=" * 40)
    
    for metrique, stats in resultats.items():
        print(f"{metrique.upper()}:")
        print(f"  Moyenne: {stats['moyenne']:.3f} Â± {stats['std']:.3f}")
        print(f"  Intervalle confiance 95%: [{stats['intervalle'][0]:.3f}, {stats['intervalle'][1]:.3f}]")
        print(f"  Scores individuels: {[f'{s:.3f}' for s in stats['scores']]}")
        print()
    
    return resultats

# Test de plusieurs modÃ¨les
modeles_test = {
    'Naive Bayes': MultinomialNB(),
    'SVM': SVC(kernel='rbf', probability=True),
    'Random Forest': RandomForestClassifier(n_estimators=100)
}

for nom, modele in modeles_test.items():
    print(f"\nğŸ¤– MODÃˆLE: {nom}")
    validation_croisee_complete(modele, X_train_vec, y_train)
```

### ğŸ“ˆ **Courbes d'Apprentissage**

```python
from sklearn.model_selection import learning_curve
import numpy as np

def tracer_courbes_apprentissage(modele, X, y, title="Courbes d'Apprentissage"):
    """Trace les courbes d'apprentissage pour dÃ©tecter overfitting/underfitting"""
    
    train_sizes, train_scores, val_scores = learning_curve(
        modele, X, y, 
        train_sizes=np.linspace(0.1, 1.0, 10),
        cv=5, 
        scoring='f1_weighted',
        n_jobs=-1
    )
    
    # Calcul des moyennes et Ã©carts-types
    train_mean = train_scores.mean(axis=1)
    train_std = train_scores.std(axis=1)
    val_mean = val_scores.mean(axis=1)
    val_std = val_scores.std(axis=1)
    
    # Graphique
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Score EntraÃ®nement')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.3, color='blue')
    
    plt.plot(train_sizes, val_mean, 'o-', color='red', label='Score Validation')
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.3, color='red')
    
    plt.xlabel('Taille du dataset d\'entraÃ®nement')
    plt.ylabel('Score F1')
    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # InterprÃ©tation automatique
    gap_final = train_mean[-1] - val_mean[-1]
    
    print(f"ğŸ“Š ANALYSE DES COURBES:")
    print(f"Score final entraÃ®nement: {train_mean[-1]:.3f}")
    print(f"Score final validation: {val_mean[-1]:.3f}")
    print(f"Gap train/val: {gap_final:.3f}")
    
    if gap_final > 0.1:
        print("âš ï¸  OVERFITTING dÃ©tectÃ© ! Le modÃ¨le apprend par cÅ“ur.")
        print("ğŸ’¡ Solutions: rÃ©gularisation, plus de donnÃ©es, early stopping")
    elif val_mean[-1] < 0.7:
        print("âš ï¸  UNDERFITTING dÃ©tectÃ© ! Le modÃ¨le est trop simple.")
        print("ğŸ’¡ Solutions: features plus complexes, modÃ¨le plus puissant")
    else:
        print("âœ… ModÃ¨le bien Ã©quilibrÃ© !")
    
    plt.show()

# Test sur nos modÃ¨les
for nom, modele in modeles_test.items():
    tracer_courbes_apprentissage(modele, X_train_vec, y_train, f"Courbes - {nom}")
```

### ğŸ¯ **DÃ©tection des Erreurs Typiques**

```python
def analyser_erreurs(modele, X_test, y_test, X_test_texte):
    """Analyse dÃ©taillÃ©e des erreurs pour amÃ©lioration"""
    
    predictions = modele.predict(X_test)
    probas = modele.predict_proba(X_test)
    
    # 1. Erreurs avec faible confiance
    erreurs_faible_confiance = []
    
    for i, (vraie, pred) in enumerate(zip(y_test, predictions)):
        if vraie != pred:
            confiance = max(probas[i])
            erreurs_faible_confiance.append({
                'index': i,
                'texte': X_test_texte[i],
                'vraie_classe': vraie,
                'pred_classe': pred, 
                'confiance': confiance
            })
    
    # Tri par confiance croissante
    erreurs_faible_confiance.sort(key=lambda x: x['confiance'])
    
    print("ğŸ” TOP 10 ERREURS AVEC FAIBLE CONFIANCE")
    print("=" * 50)
    
    for i, erreur in enumerate(erreurs_faible_confiance[:10]):
        print(f"\n{i+1}. Confiance: {erreur['confiance']:.2%}")
        print(f"   Texte: {erreur['texte'][:100]}...")
        print(f"   Vraie classe: {erreur['vraie_classe']}")
        print(f"   PrÃ©diction: {erreur['pred_classe']}")
    
    # 2. Analyse des confusions frÃ©quentes
    cm = confusion_matrix(y_test, predictions)
    classes = ['nÃ©gatif', 'neutre', 'positif']
    
    print(f"\nâŒ CONFUSIONS LES PLUS FRÃ‰QUENTES")
    print("=" * 35)
    
    confusions = []
    for i in range(len(classes)):
        for j in range(len(classes)):
            if i != j and cm[i][j] > 0:
                confusions.append((classes[i], classes[j], cm[i][j]))
    
    confusions.sort(key=lambda x: x[2], reverse=True)
    
    for vraie, pred, nb in confusions[:5]:
        print(f"{vraie} â†’ {pred}: {nb} erreurs")
    
    return erreurs_faible_confiance

# Analyse des erreurs
erreurs = analyser_erreurs(best_modele, X_test_vec, y_test, X_test)
```

---

## ğŸ’» **Exercices Pratiques**

### ğŸ“ **Exercice 9 : Classification Naive Bayes**
**Objectif :** MaÃ®triser l'algorithme de base de la classification de texte  
**DifficultÃ© :** â­â­â­â˜†â˜†  
**Temps estimÃ© :** 45 minutes

#### **Ã‰noncÃ©**
CrÃ©ez un classificateur de sentiments binaire (positif/nÃ©gatif) en utilisant Naive Bayes sur un dataset d'avis clients.

#### **Dataset Fourni**
- **avis_clients_binaire.csv** : 2000 avis (1000 positifs, 1000 nÃ©gatifs)
- Colonnes : `texte`, `sentiment`

#### **TÃ¢ches Ã  RÃ©aliser**
1. **Exploration** : Analysez la distribution et la longueur des textes
2. **Preprocessing** : Nettoyez les donnÃ©es avec la pipeline du module
3. **Vectorisation** : Testez diffÃ©rentes configurations TF-IDF
4. **EntraÃ®nement** : Naive Bayes avec optimisation des hyperparamÃ¨tres
5. **Ã‰valuation** : MÃ©triques complÃ¨tes + analyse d'erreurs

#### **Code Template**
```python
# Votre code ici - template fourni dans /exercices/exercice-09/
import pandas as pd
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# 1. Chargement des donnÃ©es
df = pd.read_csv('datasets/avis_clients_binaire.csv')

# 2. TODO: Exploration des donnÃ©es
# Votre code ici

# 3. TODO: Preprocessing
# Votre code ici

# 4. TODO: Split et vectorisation  
# Votre code ici

# 5. TODO: EntraÃ®nement Naive Bayes
# Votre code ici

# 6. TODO: Ã‰valuation complÃ¨te
# Votre code ici
```

#### **CritÃ¨res de RÃ©ussite**
- [ ] F1-Score > 0.85 sur le test set
- [ ] Analyse d'au moins 3 configurations TF-IDF diffÃ©rentes
- [ ] Identification des 10 mots les plus discriminants
- [ ] Code propre et commentÃ©

---

### ğŸ“ **Exercice 10 : Feature Engineering pour Sentiments**
**Objectif :** CrÃ©er des features custom qui amÃ©liorent la performance  
**DifficultÃ© :** â­â­â­â­â˜†  
**Temps estimÃ© :** 60 minutes

#### **Ã‰noncÃ©**
DÃ©veloppez un systÃ¨me de features personnalisÃ©es qui capture les nuances Ã©motionnelles et testez leur impact sur la performance.

#### **Dataset**
- **tweets_sentiments.csv** : 5000 tweets annotÃ©s (positif/nÃ©gatif/neutre)
- DÃ©fi : Textes courts avec emojis, argot, nÃ©gations

#### **Features Ã  ImplÃ©menter**
1. **Ã‰motionnelles** : Score des mots positifs/nÃ©gatifs, ratio d'Ã©mojis
2. **Linguistiques** : Longueur, ponctuation, majuscules  
3. **NÃ©gations** : Transformation des constructions nÃ©gatives
4. **N-grammes** : Bigrammes et trigrammes contextuels
5. **Custom** : Une feature innovante de votre invention !

#### **Analyse Requise**
```python
# Comparaison obligatoire
configurations = [
    "TF-IDF seul",
    "TF-IDF + Features basiques", 
    "TF-IDF + Features Ã©motionnelles",
    "TF-IDF + Toutes features custom",
    "Features custom seulement"
]

# Pour chaque config : F1-score + temps d'entraÃ®nement
```

#### **Bonus Challenge**
CrÃ©ez une feature qui dÃ©tecte le sarcasme/ironie (indices : guillemets, patterns linguistiques)

#### **CritÃ¨res de RÃ©ussite**
- [ ] AmÃ©lioration de +5% minimum avec features custom
- [ ] Pipeline rÃ©utilisable et modulaire
- [ ] Analyse de l'importance des features
- [ ] Documentation des choix de design

---

### ğŸ“ **Exercice 11 : Validation CroisÃ©e et Optimisation**
**Objectif :** MaÃ®triser l'Ã©valuation rigoureuse et l'optimisation d'hyperparamÃ¨tres  
**DifficultÃ© :** â­â­â­â­â˜†  
**Temps estimÃ© :** 45 minutes

#### **Ã‰noncÃ©**
Comparez scientifiquement 3 algorithmes de classification et optimisez le meilleur avec Grid Search et validation croisÃ©e.

#### **Algorithmes Ã  Tester**
1. **Naive Bayes** : MultinomialNB avec lissage
2. **SVM** : Kernel RBF avec rÃ©gularisation
3. **Random Forest** : Ensemble avec profondeur variable

#### **Protocole d'Ã‰valuation**
```python
# Validation croisÃ©e stratifiÃ©e 5-fold
# MÃ©triques : Accuracy, Precision, Recall, F1 (weighted)
# Analyse statistique : moyenne Â± Ã©cart-type
# Test de significativitÃ© entre modÃ¨les
```

#### **Grid Search Requis**
```python
param_grids = {
    'nb': {'alpha': [0.1, 0.5, 1.0, 2.0]},
    'svm': {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']},
    'rf': {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, None]}
}
```

#### **Livrables**
- Tableau comparatif avec intervalles de confiance
- Courbes d'apprentissage pour le meilleur modÃ¨le
- Analyse du temps de calcul vs performance
- Recommandation justifiÃ©e pour la production

#### **CritÃ¨res de RÃ©ussite**
- [ ] Validation croisÃ©e correctement implÃ©mentÃ©e
- [ ] Grid search exhaustif sur les 3 modÃ¨les
- [ ] Analyse statistique des diffÃ©rences
- [ ] Visualisations professionnelles

---

### ğŸ“ **Exercice 12 : Optimisation AvancÃ©e et Diagnostic**
**Objectif :** Diagnostiquer et corriger les problÃ¨mes de performance  
**DifficultÃ© :** â­â­â­â­â­  
**Temps estimÃ© :** 75 minutes

#### **Ã‰noncÃ©**
Vous recevez un modÃ¨le "cassÃ©" avec de mauvaises performances. Diagnostiquez les problÃ¨mes et proposez des solutions.

#### **ScÃ©nario**
```python
# ModÃ¨le fourni avec problÃ¨mes volontaires :
modele_casse = {
    "f1_score": 0.45,  # TrÃ¨s faible !
    "train_accuracy": 0.95,  # Suspect...
    "val_accuracy": 0.50,   # Overfitting Ã©vident
    "problemes": ["donnÃ©es dÃ©sÃ©quilibrÃ©es", "features inadaptÃ©es", "hyperparamÃ¨tres sous-optimaux"]
}
```

#### **Mission de Diagnostic**
1. **Analyse des DonnÃ©es**
   - Distribution des classes
   - QualitÃ© des annotations
   - PrÃ©sence de doublons/bruit

2. **Diagnostic du ModÃ¨le**
   - Courbes d'apprentissage
   - Matrice de confusion dÃ©taillÃ©e
   - Analyse des erreurs par classe

3. **Solutions d'AmÃ©lioration**
   - RÃ©Ã©quilibrage des donnÃ©es
   - Feature engineering ciblÃ©
   - RÃ©gularisation appropriÃ©e
   - Ensemble methods

#### **Optimisations Ã  Tester**
```python
strategies_amelioration = [
    "SMOTE pour rÃ©Ã©quilibrage",
    "Feature selection avec chi2",
    "Regularisation L1/L2",
    "Ensemble Voting/Bagging",
    "Threshold tuning",
    "Calibration des probabilitÃ©s"
]
```

#### **Rapport Final Requis**
- Diagnostic des problÃ¨mes identifiÃ©s
- Impact quantifiÃ© de chaque amÃ©lioration
- Recommandations pour Ã©viter ces problÃ¨mes
- Code optimisÃ© final avec documentation

#### **CritÃ¨res de RÃ©ussite**
- [ ] AmÃ©lioration du F1-score Ã  >0.80
- [ ] Ã‰limination de l'overfitting (gap <0.05)
- [ ] Documentation complÃ¨te du processus
- [ ] Propositions innovantes d'amÃ©lioration

---

## ğŸš€ **Projet Final : Analyseur de Sentiments Multi-Classes**

### ğŸ¯ **Objectif Global**
CrÃ©er un analyseur de sentiments professionnel capable de traiter du texte en temps rÃ©el et de fournir des insights business.

### ğŸ“‹ **Cahier des Charges**

#### **FonctionnalitÃ©s Obligatoires**
1. **Classification Multi-Classes** : Positif/NÃ©gatif/Neutre avec scores de confiance
2. **API REST** : Endpoint pour analyse en temps rÃ©el
3. **Interface Web** : Upload de fichiers CSV + analyse en batch
4. **Visualisations** : Graphiques de distribution des sentiments
5. **Export** : RÃ©sultats en JSON/CSV avec mÃ©triques dÃ©taillÃ©es

#### **SpÃ©cifications Techniques**
```python
# Architecture imposÃ©e
projet_structure = {
    "modele/": "Pipeline d'entraÃ®nement + modÃ¨le sauvegardÃ©",
    "api/": "FastAPI avec endpoints documentÃ©s",
    "interface/": "Streamlit pour demo interactive", 
    "tests/": "Tests unitaires + tests d'intÃ©gration",
    "data/": "Datasets + preprocessing pipeline",
    "docs/": "Documentation technique complÃ¨te"
}
```

#### **Performance Minimale Requise**
- **F1-Score** : >0.75 sur test set multi-classes
- **Latence API** : <200ms par requÃªte
- **Robustesse** : Gestion des erreurs et cas limites
- **ScalabilitÃ©** : Traitement de 1000+ textes en batch

### ğŸ› ï¸ **Template de DÃ©marrage**

#### **Structure du Projet**
```
analyseur-sentiments/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ logging.conf
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â””â”€â”€ datasets.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ prediction.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â””â”€â”€ interface/
â”‚       â”œâ”€â”€ app.py
â”‚       â””â”€â”€ components.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploration.ipynb
â”‚   â”œâ”€â”€ training.ipynb
â”‚   â””â”€â”€ evaluation.ipynb
â””â”€â”€ models/
    â”œâ”€â”€ vectorizer.pkl
    â”œâ”€â”€ classifier.pkl
    â””â”€â”€ metadata.json
```

#### **API Template (FastAPI)**
```python
# src/api/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
import joblib

app = FastAPI(title="Analyseur de Sentiments", version="1.0.0")

# ModÃ¨les chargÃ©s au dÃ©marrage
vectorizer = joblib.load("models/vectorizer.pkl")
classifier = joblib.load("models/classifier.pkl")

class TexteInput(BaseModel):
    texte: str

class SentimentOutput(BaseModel):
    sentiment: str
    confiance: float
    scores: dict

@app.post("/analyser", response_model=SentimentOutput)
async def analyser_sentiment(input_data: TexteInput):
    """Analyse le sentiment d'un texte"""
    try:
        # TODO: ImplÃ©menter la logique d'analyse
        pass
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyser_batch", response_model=List[SentimentOutput])
async def analyser_batch(textes: List[TexteInput]):
    """Analyse multiple textes en une fois"""
    # TODO: ImplÃ©menter l'analyse en lot
    pass
```

#### **Interface Streamlit Template**
```python
# src/interface/app.py
import streamlit as st
import requests
import pandas as pd
import plotly.express as px

st.title("ğŸ¯ Analyseur de Sentiments Pro")

# Sidebar pour configuration
st.sidebar.header("Configuration")
api_url = st.sidebar.text_input("URL API", "http://localhost:8000")

# Onglets pour diffÃ©rents modes
tab1, tab2, tab3 = st.tabs(["ğŸ“ Texte Simple", "ğŸ“Š Analyse Batch", "ğŸ“ˆ Dashboard"])

with tab1:
    st.header("Analyse d'un texte")
    texte_input = st.text_area("Entrez votre texte Ã  analyser:")
    
    if st.button("Analyser"):
        if texte_input:
            # TODO: Appel API + affichage rÃ©sultats
            pass

with tab2:
    st.header("Analyse en lot")
    fichier = st.file_uploader("Upload CSV", type=['csv'])
    
    if fichier:
        # TODO: Traitement batch + visualisations
        pass

with tab3:
    st.header("Dashboard Analytics")
    # TODO: MÃ©triques globales + graphiques
    pass
```

### ğŸ“Š **CritÃ¨res d'Ã‰valuation**

| CritÃ¨re | Poids | DÃ©tail |
|---------|-------|--------|
| **Performance Technique** | 30% | F1-score, robustesse, optimisation |
| **Architecture** | 25% | Code modulaire, tests, documentation |
| **Interface Utilisateur** | 20% | UX/UI, facilitÃ© d'usage |
| **Innovation** | 15% | Features originales, amÃ©lirations |
| **Documentation** | 10% | README, API docs, guide utilisateur |

### ğŸ† **Bonus Points**

- **ğŸš€ DÃ©ploiement** : Application dÃ©ployÃ©e sur Heroku/Streamlit Cloud (+5 pts)
- **ğŸ§ª A/B Testing** : Comparaison de modÃ¨les avec mÃ©triques (+3 pts)
- **ğŸ¨ Design** : Interface particuliÃ¨rement soignÃ©e (+2 pts)
- **âš¡ Performance** : Optimisations avancÃ©es (caching, async) (+3 pts)
- **ğŸ“± Mobile** : Interface responsive/mobile-friendly (+2 pts)

---

## ğŸ“š **Ressources et Outils**

### ğŸ“¦ **Packages Essentiels**
```python
# requirements.txt du module
scikit-learn==1.3.0      # Algorithmes ML
pandas==2.0.3            # Manipulation donnÃ©es  
numpy==1.24.3            # Calculs numÃ©riques
matplotlib==3.7.1        # Visualisations de base
seaborn==0.12.2          # Visualisations avancÃ©es
plotly==5.15.0           # Graphiques interactifs

# NLP spÃ©cialisÃ©
nltk==3.8.1              # Outils linguistiques
spacy==3.6.1             # NLP moderne
textblob==0.17.1         # Sentiment analysis simple

# API et interface
fastapi==0.100.1         # API REST moderne
streamlit==1.25.0        # Interface web rapide
uvicorn==0.23.2          # Serveur ASGI

# Utilitaires
joblib==1.3.1            # SÃ©rialisation modÃ¨les
tqdm==4.65.0             # Barres de progression
jupyter==1.0.0           # Notebooks
```

### ğŸ“Š **Datasets Fournis**

#### **Dataset Principal : Avis Multi-Domaines**
```
avis_multidomaines.csv (10,000 entrÃ©es)
â”œâ”€â”€ colonnes: texte, sentiment, domaine, longueur
â”œâ”€â”€ sentiments: positif (40%), neutre (20%), nÃ©gatif (40%)  
â”œâ”€â”€ domaines: e-commerce, restaurants, films, tech, voyage
â””â”€â”€ challenge: variabilitÃ© de vocabulaire entre domaines
```

#### **Dataset Challenge : Tweets en Temps RÃ©el**
```
tweets_realtime.csv (5,000 entrÃ©es)
â”œâ”€â”€ dÃ©fis: emojis, argot, fautes, sarcasme
â”œâ”€â”€ annotation: crowd-sourcing avec accord inter-annotateurs
â””â”€â”€ mÃ©tadonnÃ©es: timestamp, nb_retweets, nb_likes
```

#### **Dataset Validation : Avis Produits Amazon**
```
amazon_reviews_fr.csv (3,000 entrÃ©es)
â”œâ”€â”€ structure: review_text, rating (1-5 Ã©toiles)
â”œâ”€â”€ conversion: 1-2â˜…